{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n",
      "556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from GP_MLP import GP_MLP\n",
    "from Autoencoder import Autoencoder\n",
    "from read import VideoReader as VR\n",
    "from Generator import Generator\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "theano.config.optimizer='None'\n",
    "theano.config.floatX='float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(object):\n",
    "    def __init__(self,memory,time_step,h_size,n_hid,mlp_hid,lr,video_inp,video_size,srng):\n",
    "        self.gp_mlp = GP_MLP(memory = memory,\n",
    "                             srng=srng,\n",
    "                        n_in = time_step,\n",
    "                        n_hid = mlp_hid,\n",
    "                             n_out = h_size)\n",
    "        #self.gen = Autoencoder(video_size,h_size,video_inp)\n",
    "        self.gen= Generator(x=video_inp,time_step = time_step)\n",
    "        self.n_in = h_size\n",
    "        self.n_hid = n_hid\n",
    "        self.n_out = 1\n",
    "        self.srng = srng\n",
    "        self.factor = 1\n",
    "        u_gp = self.gp_mlp.mlp_out\n",
    "        u_gp.name = \"GP_input\"\n",
    "        u_auto = self.gen.latent.output\n",
    "        u_auto.name=\"Auto_latent\"\n",
    "        #u_auto = self.gen.latent\n",
    "        self.get_auto = theano.function([video_inp],u_auto)\n",
    "        # initial hidden state of the RNN\n",
    "        h0 = theano.shared(numpy.zeros(self.n_hid,),name=\"RNN_h0\")\n",
    "        # learning rate\n",
    "        lr = lr\n",
    "        # recurrent weights as a shared variable\n",
    "        W = theano.shared(numpy.random.uniform(-numpy.sqrt(6/(self.n_hid + self.n_out)),numpy.sqrt(6/(self.n_hid + self.n_out)),size=(self.n_hid, self.n_hid) ),name=\"W_hh\")\n",
    "        b = theano.shared(numpy.zeros(shape=(self.n_hid,)),name=\"b_hh\")\n",
    "        # input to hidden layer weights\n",
    "        W_in = theano.shared(numpy.random.uniform(-numpy.sqrt(6/(self.n_hid + self.n_out)),numpy.sqrt(6/(self.n_hid + self.n_out)),size=(self.n_in, self.n_hid) ),name=\"W_in\")\n",
    "        b_in = theano.shared(numpy.zeros(shape=(self.n_hid,)),name=\"b_in\")\n",
    "        # hidden to output layer weights\n",
    "        W_out = theano.shared(numpy.random.uniform(-numpy.sqrt(24/(self.n_hid + self.n_out)),numpy.sqrt(24/(self.n_hid + self.n_out)),size=(self.n_hid, self.n_out) ),name=\"W_out\")\n",
    "        b_out = theano.shared(numpy.zeros(shape=(self.n_out,)),name=\"b_out\")\n",
    "        pos_time = theano.shared(numpy.ones((time_step,1)),name=\"pos\")\n",
    "        neg_time = theano.shared(numpy.zeros((time_step,1)),name=\"neg\")\n",
    "        [_, y_gp], _ = theano.scan(self.step,\n",
    "                        sequences=u_gp,\n",
    "                        outputs_info=[h0, None],\n",
    "                        non_sequences=[W, W_in, W_out,b_in,b_out])\n",
    "        [_, y_auto], _ = theano.scan(self.step,\n",
    "                        sequences=u_auto,\n",
    "                        outputs_info=[h0, None],\n",
    "                        non_sequences=[W, W_in, W_out,b_in,b_out])\n",
    "        # the hidden state `h` for the entire sequence, and the output for the\n",
    "        # entrie sequence `y` (first dimension is always time)\n",
    "        # error between output and target\n",
    "        #error_lat = ((y_latent - pos_time) ** 2).sum()\n",
    "        y_gp.name=\"output_gp_RNN\"\n",
    "        #error_pos = (cross_entropy(y_gp, pos_time))*1.0\n",
    "        #cross_entr = (cross_entropy(y_gp, neg_time)  + cross_entropy(y_auto, pos_time))/2\n",
    "        error_pos = T.sum(T.sum(((y_gp-pos_time))**2))*1.0\n",
    "        cross_entr = (T.sum((y_gp- neg_time)**2)  + T.sum((y_auto- pos_time)**2))/2\n",
    "        error_neg = cross_entr + 0.001*(abs(W**2).sum())+(abs(W_in**2).sum())+((W_out**2).sum())\n",
    "        # gradients on the weights using BPTT\n",
    "        gW, gW_in, gW_out = T.grad(error_neg, [W, W_in, W_out])\n",
    "        # training function, that computes the error and updates the weights using\n",
    "        # SGD.\n",
    "        grads=[]\n",
    "        params=[W,W_in,W_out,b_in,b_out]\n",
    "        print [x.dtype for x in params]\n",
    "        for param in params:\n",
    "            grads.append(T.grad(error_neg,param))\n",
    "        print [x.dtype for x in grads]\n",
    "        print error_neg.dtype\n",
    "        self.update = []\n",
    "        for param,grad in zip(params,grads):\n",
    "            self.update.append((param,param-grad*lr))\n",
    "        \n",
    "\n",
    "        gp_grads=[]\n",
    "        for param in self.gp_mlp.params:\n",
    "            gp_grads.append(T.grad(error_pos,param))\n",
    "        self.gp_update = []\n",
    "        for param,grad in zip(self.gp_mlp.params,gp_grads):\n",
    "            self.gp_update.append((param,param-grad*lr*self.factor))\n",
    "\n",
    "        self.disc_auto_update=[]\n",
    "        disc_auto_grads=[]\n",
    "        for param in self.gen.encoder_params:\n",
    "            disc_auto_grads.append(T.grad(error_neg,param))\n",
    "        for param,grad in zip(self.gen.encoder_params,disc_auto_grads):\n",
    "            self.disc_auto_update.append((param,param-grad*lr))\n",
    "\n",
    "            \n",
    "        self.train_auto = theano.function([video_inp],self.gen.cost,updates=self.gen.update,allow_input_downcast=True)\n",
    "        self.train_disc_auto = theano.function([video_inp],error_neg,updates=self.disc_auto_update,allow_input_downcast=True)\n",
    "        self.train_disc = theano.function([video_inp],\n",
    "                                          error_neg,\n",
    "                                          updates = self.update,\n",
    "                                          allow_input_downcast=True)\n",
    "\n",
    "        self.train_gp = theano.function([],\n",
    "                                        error_pos,\n",
    "                                        updates = self.gp_update,allow_input_downcast=True\n",
    "        )\n",
    "        \n",
    "        self.train_out = theano.function([],\n",
    "                                         y_gp\n",
    "        )\n",
    "        self.get_auto = theano.function([video_inp],self.gen.cost,allow_input_downcast=True)\n",
    "        self.get_disc_auto = theano.function([video_inp],error_neg,allow_input_downcast=True)\n",
    "        self.get_disc = theano.function([video_inp],\n",
    "                                          cross_entr,\n",
    "                                          allow_input_downcast=True)\n",
    "\n",
    "        self.get_gp = theano.function([],\n",
    "                                        error_pos,allow_input_downcast=True\n",
    "        )\n",
    "\n",
    "        self.total_params = [W,W_in,W_out]+self.gp_mlp.params+self.gen.params+[b_in,b,b_out]\n",
    "        print \"Discrminator built\"\n",
    "    def step(self,u_t, h_tm1, W, W_in, W_out,b_in,b_out):\n",
    "        h_t1 = T.nnet.relu(T.dot(u_t, W_in)+b_in,alpha=0.2)\n",
    "        h_t = T.nnet.relu(h_t1+ T.dot(h_tm1, W),alpha=0.2)\n",
    "        y_t = T.nnet.sigmoid(T.dot(h_t, W_out)+b_out)\n",
    "        return h_t, y_t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cPickle\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "mypath='../data'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "theano.config.optimizer='None'\n",
    "time_step = 50\n",
    "eps=0.0\n",
    "video_inp = T.matrix(\"video_inp\")\n",
    "srng = RandomStreams(seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disc = Discriminator(memory=1000,time_step=time_step,h_size=500,n_hid=1000,mlp_hid=1000,lr=0.0001,video_size=80*60,video_inp=video_inp,srng=srng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vid=0\n",
    "for l in range(0,10000):\n",
    "    for f in onlyfiles:\n",
    "        vr = VR('../data/'+f)\n",
    "        count = vr.count_frame()\n",
    "        vr = VR('../data/'+f)\n",
    "        for j in range(0,count-time_step-1):\n",
    "            input=[]\n",
    "            for i in range(0,time_step):\n",
    "                input.append(numpy.asarray(cv2.resize(vr.return_frame(j+1),(80,60)).flatten()))\n",
    "            new_matrix = (input - numpy.min(input))/(numpy.max(input)-numpy.min(input)*1.0)\n",
    "            input = new_matrix.T\n",
    "            reconstruction_err =  disc.train_auto(input)\n",
    "            disc_err = disc.get_disc(input)\n",
    "            fool_err = disc.get_gp()\n",
    "            print disc.train_out()\n",
    "            if disc_err <= fool_err:\n",
    "                fooling_err = disc.train_gp()\n",
    "                print \"Epoch no.: [%d] Iteration number: [%d] \\n \\tDiscriminator error: %lf, \\n \\tReconstruction Error: %lf, \\n \\tFooling is stopped: %lf\" %(l,count_vid,disc_err,reconstruction_err,fool_err)\n",
    "            if disc_err >= fool_err:\n",
    "                discriminator_err = disc.train_disc(input)\n",
    "                print \"Epoch no.: [%d] Iteration number: [%d] \\n \\tDiscrimination error :%lf \\n \\tReconstruction Erros: %d\\n \\tFooling Error:%d\" %(l,count_vid,disc_err,reconstruction_err,fool_err)\n",
    "            disc.train_disc_auto(input)\n",
    "            print disc.W_hh.eval()\n",
    "            \n",
    "        #    if count_vid%10==0:\n",
    "        #        file_name = 'params'+'.pkl'\n",
    "        #f = file(file_name, 'wb')\n",
    "        #        //cPickle.dump(disc.total_params, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "        #        f.close()\n",
    "        #    count_vid +=1\n",
    "        l = l+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
